{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "import sklearn.exceptions\n",
    "warnings.filterwarnings(\"ignore\", category=sklearn.exceptions.UndefinedMetricWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset features\n",
    "buying price: v-high, high, med, low\n",
    "\n",
    "maintenance price: v-high, high, med, low\n",
    "\n",
    "number of doors: 2, 3, 4, 5-more\n",
    "\n",
    "person capacity: 2, 4, more\n",
    "\n",
    "luggage boot: small, med, big\n",
    "\n",
    "safety: low, med, high\n",
    "\n",
    "acceptability: unacc, acc, good, v-good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of cars in the dataset: 1728\n"
     ]
    }
   ],
   "source": [
    "cars_data = pd.read_csv(\"cars.csv\")\n",
    "print('Number of cars in the dataset: {}'.format(cars_data.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>buying price</th>\n",
       "      <th>maintenance price</th>\n",
       "      <th>number of doors</th>\n",
       "      <th>person capacity</th>\n",
       "      <th>luggage boot</th>\n",
       "      <th>safety</th>\n",
       "      <th>acceptability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>low</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>med</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>high</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>med</td>\n",
       "      <td>low</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>med</td>\n",
       "      <td>med</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  buying price maintenance price number of doors person capacity luggage boot  \\\n",
       "0        vhigh             vhigh               2               2        small   \n",
       "1        vhigh             vhigh               2               2        small   \n",
       "2        vhigh             vhigh               2               2        small   \n",
       "3        vhigh             vhigh               2               2          med   \n",
       "4        vhigh             vhigh               2               2          med   \n",
       "\n",
       "  safety acceptability  \n",
       "0    low         unacc  \n",
       "1    med         unacc  \n",
       "2   high         unacc  \n",
       "3    low         unacc  \n",
       "4    med         unacc  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cars_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Initial Analysis of the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1728 entries, 0 to 1727\n",
      "Data columns (total 7 columns):\n",
      " #   Column             Non-Null Count  Dtype \n",
      "---  ------             --------------  ----- \n",
      " 0   buying price       1728 non-null   object\n",
      " 1   maintenance price  1728 non-null   object\n",
      " 2   number of doors    1728 non-null   object\n",
      " 3   person capacity    1728 non-null   object\n",
      " 4   luggage boot       1728 non-null   object\n",
      " 5   safety             1728 non-null   object\n",
      " 6   acceptability      1728 non-null   object\n",
      "dtypes: object(7)\n",
      "memory usage: 94.6+ KB\n"
     ]
    }
   ],
   "source": [
    "# checking if data contains any Null values\n",
    "cars_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remark**: There are no Null values in the dataset!. All columns are object data types, we could convert them to categorical data indicating their true data types, to save memory, but this is a small dataset so it does not seem necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>buying price</th>\n",
       "      <th>maintenance price</th>\n",
       "      <th>number of doors</th>\n",
       "      <th>person capacity</th>\n",
       "      <th>luggage boot</th>\n",
       "      <th>safety</th>\n",
       "      <th>acceptability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1728</td>\n",
       "      <td>1728</td>\n",
       "      <td>1728</td>\n",
       "      <td>1728</td>\n",
       "      <td>1728</td>\n",
       "      <td>1728</td>\n",
       "      <td>1728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "      <td>4</td>\n",
       "      <td>more</td>\n",
       "      <td>small</td>\n",
       "      <td>low</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>432</td>\n",
       "      <td>432</td>\n",
       "      <td>432</td>\n",
       "      <td>576</td>\n",
       "      <td>576</td>\n",
       "      <td>576</td>\n",
       "      <td>1210</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       buying price maintenance price number of doors person capacity  \\\n",
       "count          1728              1728            1728            1728   \n",
       "unique            4                 4               4               3   \n",
       "top             low               low               4            more   \n",
       "freq            432               432             432             576   \n",
       "\n",
       "       luggage boot safety acceptability  \n",
       "count          1728   1728          1728  \n",
       "unique            3      3             4  \n",
       "top           small    low         unacc  \n",
       "freq            576    576          1210  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Some statistics about the dataset\n",
    "cars_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remark:** It seems that almost third of the cars in the dataset are unacceptable. \n",
    "Let's plot counts for each value in the acceptability field, to see how many cars are unacceptable, acceptable, good and very good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "unacc    1210\n",
       "acc       384\n",
       "good       69\n",
       "vgood      65\n",
       "Name: acceptability, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the count for each value of the acceptability field\n",
    "cars_data['acceptability'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install psutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Image generation requires the psutil package.\n\nInstall using pip:\n    $ pip install psutil\n\nInstall using conda:\n    $ conda install psutil\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-41f357b95cac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# plotting the number of cars on each acceptability category\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPie\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"png\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Desktop/JObs/seez_ml_exercise/seezenv/lib/python3.6/site-packages/plotly/basedatatypes.py\u001b[0m in \u001b[0;36mshow\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2869\u001b[0m         \u001b[0;32mimport\u001b[0m \u001b[0mplotly\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2870\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2871\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mpio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2872\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2873\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mto_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/JObs/seez_ml_exercise/seezenv/lib/python3.6/site-packages/plotly/io/_renderers.py\u001b[0m in \u001b[0;36mshow\u001b[0;34m(fig, renderer, validate, **kwargs)\u001b[0m\n\u001b[1;32m    375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m     \u001b[0;31m# Mimetype renderers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 377\u001b[0;31m     \u001b[0mbundle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrenderers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build_mime_bundle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderers_string\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    378\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mbundle\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mipython_display\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/JObs/seez_ml_exercise/seezenv/lib/python3.6/site-packages/plotly/io/_renderers.py\u001b[0m in \u001b[0;36m_build_mime_bundle\u001b[0;34m(self, fig_dict, renderers_string, **kwargs)\u001b[0m\n\u001b[1;32m    295\u001b[0m                         \u001b[0msetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 297\u001b[0;31m                 \u001b[0mbundle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_mimebundle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    298\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbundle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/JObs/seez_ml_exercise/seezenv/lib/python3.6/site-packages/plotly/io/_base_renderers.py\u001b[0m in \u001b[0;36mto_mimebundle\u001b[0;34m(self, fig_dict)\u001b[0m\n\u001b[1;32m    132\u001b[0m             \u001b[0mscale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m             \u001b[0mvalidate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m             \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m         )\n\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/JObs/seez_ml_exercise/seezenv/lib/python3.6/site-packages/plotly/io/_kaleido.py\u001b[0m in \u001b[0;36mto_image\u001b[0;34m(fig, format, width, height, scale, validate, engine)\u001b[0m\n\u001b[1;32m    106\u001b[0m             \u001b[0mheight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m             \u001b[0mscale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m             \u001b[0mvalidate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m         )\n\u001b[1;32m    110\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"kaleido\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/JObs/seez_ml_exercise/seezenv/lib/python3.6/site-packages/plotly/io/_orca.py\u001b[0m in \u001b[0;36mto_image\u001b[0;34m(fig, format, width, height, scale, validate)\u001b[0m\n\u001b[1;32m   1533\u001b[0m     \u001b[0;31m# Make sure orca sever is running\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;31m# -------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1535\u001b[0;31m     \u001b[0mensure_server\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1536\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1537\u001b[0m     \u001b[0;31m# Handle defaults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/JObs/seez_ml_exercise/seezenv/lib/python3.6/site-packages/plotly/io/_orca.py\u001b[0m in \u001b[0;36mensure_server\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1368\u001b[0m \u001b[0mInstall\u001b[0m \u001b[0musing\u001b[0m \u001b[0mconda\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1369\u001b[0m     \u001b[0;31m$\u001b[0m \u001b[0mconda\u001b[0m \u001b[0minstall\u001b[0m \u001b[0mpsutil\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1370\u001b[0;31m \"\"\"\n\u001b[0m\u001b[1;32m   1371\u001b[0m         )\n\u001b[1;32m   1372\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Image generation requires the psutil package.\n\nInstall using pip:\n    $ pip install psutil\n\nInstall using conda:\n    $ conda install psutil\n"
     ]
    }
   ],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "labels = ['unacc','acc','good','vgood']\n",
    "values = [1210, 384, 69, 65]\n",
    "# plotting the number of cars on each acceptability category\n",
    "fig = go.Figure(data=[go.Pie(labels=labels, values=values)])\n",
    "fig.show(\"png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remark:** 70% of the cars in the dataset are unacceptable, while good and very good classes are each less than 4% of the data. \n",
    "\n",
    "This renders the dataset as a very unbalanced one, which we should take into account when providing a solution using Machine Learning algorithms. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting cars from each value of acceptability to analyse the other features of these cars\n",
    "acc_cars = cars_data.loc[cars_data['acceptability'] == 'acc']\n",
    "unacc_cars = cars_data.loc[cars_data['acceptability'] == 'unacc']\n",
    "good_cars = cars_data.loc[cars_data['acceptability'] == 'good']\n",
    "vgood_cars = cars_data.loc[cars_data['acceptability'] == 'vgood']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to plot graph of features\n",
    "def stacked_bar_graph(title, data):\n",
    "    labels = [\"buying price\",\"maintenance price\",\"number of doors\",\"person capacity\",\"luggage boot\",\"safety\"]\n",
    "    fig1 = go.Figure(\n",
    "        data = [\n",
    "            go.Bar(name=\"lowest value\", x=labels, y=data[\"model_1\"], marker={'color': 'red'}, text=data[\"model_1\"],textposition='auto'),\n",
    "            go.Bar(name=\"medium value\", x=labels, y=data[\"model_2\"], marker={'color': 'lightsalmon'}, text=data[\"model_2\"],textposition='auto'),\n",
    "            go.Bar(name=\"high value\", x=labels, y=data[\"model_3\"], marker={'color': 'lime'}, text=data[\"model_3\"],textposition='auto'),\n",
    "            go.Bar(name=\"very high value\", x=labels, y=data[\"model_4\"], marker={'color': 'limegreen'}, text=data[\"model_4\"],textposition='auto')\n",
    "        ],\n",
    "        layout=go.Layout(title=title, yaxis_title=\"Feature's value\")\n",
    "    )\n",
    "    fig1.update_layout(barmode='stack')\n",
    "    fig1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to get the value counts of each feature for differet values of car acceptability\n",
    "def graph_data_prep(cars_acceptability_filtered):\n",
    "    buy = cars_acceptability_filtered['buying price'].value_counts()\n",
    "    maintenance = cars_acceptability_filtered['maintenance price'].value_counts()\n",
    "    doors = cars_acceptability_filtered['number of doors'].value_counts()\n",
    "    person = cars_acceptability_filtered['person capacity'].value_counts()\n",
    "    luggage = cars_acceptability_filtered['luggage boot'].value_counts()\n",
    "    safety = cars_acceptability_filtered['safety'].value_counts()\n",
    "    \n",
    "    data = {\n",
    "        \"model_1\": [buy['low'], maintenance['low'], doors['2'], person.get('2', 0), luggage.get('small',0), safety.get('low', 0)],\n",
    "        \"model_2\": [buy['med'], maintenance['med'], doors['3'], person['4'], luggage.get('med',0), safety.get('med',0)],\n",
    "        \"model_3\": [buy.get('high',0), maintenance.get('high',0), doors['4'], person['more'], luggage['big'], safety.get('high',0)],\n",
    "        \"model_4\": [buy.get('vhigh',0), maintenance.get('vhigh',0), doors['5more'], 0, 0, 0],\n",
    "    }\n",
    "    return data    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Feature Analysis\n",
    "Below are 4 different graphs showing features for each 4 acceptability category of cars (unacceptable, acceptable, good, very good).\n",
    "\n",
    "Fixing the acceptability value enables us to see which features play a significant role on the cars acceptability. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.1 Unacceptable Cars\n",
    "#### Analyses of cars' features when the cars' acceptability is Unacceptable (unacc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unacc_data = graph_data_prep(unacc_cars)\n",
    "stacked_bar_graph(\"Unacceptable Cars' Features\",unacc_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remarks:**\n",
    "\n",
    "Number of unacceptable cars: 1210\n",
    "\n",
    "From the above plot we can see that:\n",
    "* Unacceptable cars have almost equally all values of 'buying price' and 'maintenance price', with a slightly more unacceptable cars having higher value prices.\n",
    "* More unacceptable cars have the lowest value (2 doors) for the number of doors. However, there are cars with more doors that are also unacceptable.\n",
    "* Almost half of the unacceptable cars have the lowest person capacity (2 person). So, person capacity seems to be an important feature for categorizing the car as unacceptable. Similarly is the 'safety' features values.\n",
    "* More unacceptable cars have the lowest value of 'Luggage boot', but not a higher significant amount from the other values. \n",
    "\n",
    "**Note**: Buying price, maintenance price and number of doors can have 4 different values. Whereas person capacity, luggage boot and safety can have 3 different values (there is no very high value)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.2 Acceptable Cars\n",
    "#### Analyses of cars' features when the cars' acceptability is Acceptable (acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_data = graph_data_prep(acc_cars)\n",
    "stacked_bar_graph(\"Acceptable Cars' Features\",acc_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remarks:** \n",
    "\n",
    "Number of acceptable cars: 384\n",
    "\n",
    "From the above plot we can see that\n",
    "* Acceptable cars have all values of buying prices (same thing is for the maintenance price and number of doors)\n",
    "* There are no acceptable cars with the lowest value of person capacity, so we can say that it is important to not have the lowest person capacity for the car to be acceptable\n",
    "* There are not acceptable cars that have the lowest value of safety, so we can say that it is important to not have the lowest safety for the car to be acceptable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.3 Good Cars\n",
    "#### Analyses of cars' features when the cars' acceptability is Good (good)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_data = graph_data_prep(good_cars)\n",
    "stacked_bar_graph(\"Good Cars' Features\",good_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remarks:** \n",
    "\n",
    "Number of cars with acceptability 'Good': 69\n",
    "\n",
    "From the above plot we can see that\n",
    "* There are no 'Good' cars that have 'high' or 'vhigh' buying price as well as maintenance price. So having medium and low values for the prices impacts the classification of cars to have 'good' acceptability value.\n",
    "* There are no 'Good' cars that have the lowest 'person capacity'. Same is for the 'safety'. So, having medium to high values of 'person capacity' and 'safety' play a significant role in a car being classified as 'good'.\n",
    "* 'Number of doors' and 'Luggage boot' does not seem to play a significant role for cars to be classified as 'good'. There is slightly less 'good' cars having the lowest values for these two features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.3 Very Good Cars\n",
    "#### Analyses of cars' features when the cars' acceptability is Very Good (vgood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vgood_data = graph_data_prep(vgood_cars)\n",
    "stacked_bar_graph(\"Very Good Cars' Features\",vgood_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remarks:** \n",
    "\n",
    "Number of cars with acceptability very good 'v-good': 65\n",
    "\n",
    "From the above plot we can see that\n",
    "* Cars categorized with 'v-good' acceptability have low and medium values of 'buying price' and **no 'v-good' cars have high or very high 'buying price'**. Similar is the 'maintenance price' however, there are some cars that have high value of 'maintenance price' but there is no cars that have 'v-high' maintenance price.\n",
    "* **Safetly is an important feature** for cars with 'v-good' acceptability, since all of them have the highest safety value. No car with lower values of safety is categorized with 'v-good' acceptability.\n",
    "* There are no 'v-good' cars that have the lowest values of 'person capacity' or 'luggage boot'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Further Analysis\n",
    "From the above analysis and insights we can see that **'safety'**, **'person capacity'**,  and **'buying price'** have the most significance to find the cars' acceptability. With **'person capacity'** being the next important feature, while **'number of doors'** does not seem to have much significance.\n",
    "\n",
    "We can further analyse each feature and its significance with the acceptability of the cars using the **crosstab function**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Safety and Car Acceptability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "safety = pd.crosstab(cars_data['safety'], cars_data['acceptability']).reindex(['unacc','good', 'vgood','acc'], axis=1)\n",
    "safety = safety.reindex(['low','med','high'], axis=0)\n",
    "safety"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As seen from the analysis and charts above safety plays a significant role on classifiying cars acceptability. **Cars with low safety are considered less acceptable than those with higher safety.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Person-Capacity and Car Acceptability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "person_capacity = pd.crosstab(cars_data['person capacity'], cars_data['acceptability']).reindex(['unacc','good', 'vgood','acc'], axis=1)\n",
    "person_capacity = person_capacity.reindex(['2','4','more'], axis=0)\n",
    "person_capacity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again as seen from the analysis and charts above person capacity plays a significant role on classifiying cars acceptability. **Cars with less person capacity are considered less acceptable than those with higher safety.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Buying price and Car Acceptability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buying_price = pd.crosstab(cars_data['buying price'], cars_data['acceptability']).reindex(['unacc','good', 'vgood','acc'], axis=1)\n",
    "buying_price = buying_price.reindex(['low','med', 'high','vhigh'], axis=0)\n",
    "buying_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_doors = pd.crosstab(cars_data['number of doors'], cars_data['acceptability'])\n",
    "number_doors = number_doors.reindex(['2','3', '4','5more'], axis=0)\n",
    "number_doors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, same as the above anaysis, it is observed that the number of doors does not play a significant role in determining the acceptability of the cars."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data we have contains labels for the target variable thus this is a supervised machine learning problem. Also, since we have labels and known values of the target variable then we can consider this as a **classification problem**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars_data_replace = cars_data.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Data Preparation\n",
    "### Encoding the categorical values \n",
    "Firstly, all the variables values in our dataset are categorical data which are not what a machine laerning algorithm expects. Therefore, we need to convert them to numerical data.\n",
    "\n",
    "All the variables' values have a meaningful order which makes them ordinal categorical variables. Therefore, we need to encode them in such a way as to retain the ordinal nature of the variables. To do that we need to perform **ordinal encoding**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to retain the ordinal nature of the variable we need to have a mapping\n",
    "# of the categories with the numerical values\n",
    "encoding_values = {'buying price': {'vhigh': 4, 'high': 3, 'med': 2, 'low': 1},\n",
    "                   'maintenance price': {'vhigh': 4, 'high': 3, 'med': 2, 'low': 1},\n",
    "                   'number of doors': {'5more': 4, '4': 3, '3': 2, '2': 1},\n",
    "                   'person capacity': {'more': 3, '4': 2, '2': 1},\n",
    "                   'luggage boot': {'big': 3, 'med': 2, 'small': 1},\n",
    "                   'safety': {'high': 3, 'med': 2, 'low': 1},\n",
    "                   'acceptability': {'vgood': 4, 'good': 3, 'acc': 2, 'unacc': 1}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars_data_replace.replace(encoding_values, inplace=True)\n",
    "cars_data_replace.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the Test and Training data sets\n",
    "\n",
    "In order to train the model we need to prepare the training set, here I take 75% of the whole dataset and use it for training. The rest of the data (25%) will be used for testing the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars_y = cars_data_replace.iloc[:,-1]\n",
    "cars_x = cars_data_replace.iloc[:, :-1]\n",
    "# splitting data into 75% training and 25% testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(cars_x, cars_y, test_size=0.25, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 ML Algorithm "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The problem we are trying to solve is a classification problem, specifically supervised classification. Some of the machine learning algorithms that are used for solving this type of problems are Support Vector Machines (SVM), K-nearest neighbor, Naive Bayes, Decision Trees, etc.\n",
    "\n",
    "Considering that we have ordinal categorical features, and a multi class classification problem, I am approaching the solution to this problem through a Decision Tree model and a SVM model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Classifier\n",
    "Given that the data contains all ordinal categorical attributes, then using a **Decision Tree Algorithm** seems to be the right choice since this algorithm is suitable for use when feature values are categorical.\n",
    "Additionally, it is suitable given that some attributes, such as safety, as seen from the analyses above play a more significant role on the cars classification than others, and knowing that this is how decision trees work, by selecting more significant features to split the dataset, makes this a suitable ML algorithm.\n",
    "\n",
    "Since 70% of the data belongs to one target class (unacceptable) it makes up for very unbalanced classes in the dataset. This can lead to a biased tree since the frequently occured classes are prefered over the less frequently occuring ones. Specifying class weight to give more importance to the less represented classes can help give the unbalanced classes a similar role in the purity of nodes. We can do this by setting the *class_weight* to 'balanced'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parameter tuning and cross validation\n",
    "Parameters of Decision Tree that we are going to optimize for here are *max_depth* which signifies the depth of the tree, and the criterion which the algorithm will use to split the data into subsets (sub-nodes) while creating the tree.\n",
    "\n",
    "I will use *GridSearchCV* functionality of sklearn to perform cross-validation and parameter tuning to find the best parameters on which we can train the Decision Tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid of paramters to choose from\n",
    "param_grid = { 'criterion':['gini','entropy'],'max_depth': np.arange(3, 20)}\n",
    "DT_classifier = GridSearchCV(DecisionTreeClassifier(random_state=0), param_grid, cv=10)\n",
    "DT_classifier.fit(X_train, y_train)\n",
    "tree_model = DT_classifier.best_estimator_\n",
    "print (DT_classifier.best_params_) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create and train the model\n",
    "DT_classifier = DecisionTreeClassifier(criterion = 'gini',class_weight = 'balanced', max_depth=11, random_state = 0)\n",
    "DT_classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluating the Decision Tree**\n",
    "\n",
    "To assess the performace of the Desision Tree model we check for the accuray, precision, recall, f1 score, as well as the confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions of the test set\n",
    "y_pred = DT_classifier.predict(X_test)\n",
    "# calculate different metrics to evaluate the model\n",
    "DT_classifier_f1 = f1_score(y_test,y_pred, average='macro')\n",
    "print(classification_report(y_test,y_pred))\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"Training Accuracy: \",DT_classifier.score(X_train, y_train))\n",
    "print(\"Testing Accuracy: \", DT_classifier.score(X_test, y_test))\n",
    "print(\"Confusion Matrix: \\n\",cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see that the accuracy is really high, but accuracy is not a good measure for our model given that our dataset is very unbalanced, and the algorithm is designed to maximize for accuracy and reduce error. For better evaluation of our model we can look at the precision, recall, f1 score and confusion matrix since they give better insights. Therefore, the precision and recall seem to be very high for all 4 target classes. Additionally, the confusion matrix shows an almost perfect diagonal (perfect classifier) which indicates that the model is performing well. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM Model\n",
    "\n",
    "Another approach to classify cars in this dataset is using Support Vector Machines (SVMs). SVMs try to find a hyperplane in an n-dimensional space that separates the data points to their potential classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Parameter Tuning\n",
    "SVM parameters that need optimizing are **C parameter** which adds a penalty for each misclassified data point, and **Gamma parameter** which controls the distance of influence of a single training point. Again as above, we can find the best parameters utilizing the *GridSearchCV* functionality of sklearn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since I will be evaluating SVM using the rbf kernel function, I am applying scaling so that the features fall in the same range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc = StandardScaler()\n",
    "# scaling the data\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameter tuning: function to find the best SVM parameters and kernel\n",
    "def best_svm_parameters():\n",
    "    print(\"Tuning hyper-parameters...\")\n",
    "    # scores to use to evalute while finding the best parameters\n",
    "    scores = ['precision','recall']\n",
    "    # parameters for which to tune and their grid values\n",
    "    tuned_parameters = [{'kernel': ['rbf'], 'gamma': [1e-2, 1e-3, 1e-4, 1e-5], \n",
    "                         'C': [0.001, 0.10, 0.1, 10, 25, 50, 100, 1000]},\n",
    "                        {'kernel': ['sigmoid'], 'gamma': [1e-2, 1e-3, 1e-4, 1e-5],\n",
    "                         'C': [0.001, 0.10, 0.1, 10, 25, 50, 100, 1000]},\n",
    "                        {'kernel': ['linear'], 'C': [0.001, 0.10, 0.1, 10, 25, 50, 100, 1000]}\n",
    "                       ]\n",
    "    for score in scores:\n",
    "        grid_search = GridSearchCV(SVC(C=1), tuned_parameters, cv=10, scoring='%s_macro' % score)\n",
    "        grid_search.fit(X_train, y_train)\n",
    "    print(\"Best parameters for SVM are:\")\n",
    "    return grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_svm_parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now train the SVM model with the best hyper-parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# SVM using the radial basis as kernel function with the best C and Gamma parameters\n",
    "rbf_svm = SVC(C=1000, gamma=0.01, kernel = 'rbf', random_state = 0)\n",
    "rbf_svm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To evaluate the SVM model we can check the values for the accuracy, precision, recall, f1 score as well as the confusion matrix which shows the true classified cases and the mistakes that the model has made on the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to evaluate the SVM by calculating the precision, recall, f1 score and the confusion matrix\n",
    "def evaluating_svm(clf):\n",
    "    y_pred = clf.predict(X_test)\n",
    "    f1_svm_linear=f1_score(y_test,y_pred, average='macro')\n",
    "    print(classification_report(y_test,y_pred))\n",
    "    print(\"Training Accuracy: \",clf.score(X_train, y_train))\n",
    "    print(\"Testing Accuracy: \", clf.score(X_test, y_test))\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    print(\"Confusion Matrix: \\n\", cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluating_svm(rbf_svm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The confusion matrix shows that the model is performing really good, since there are 17 data points where the model has made mistakes in classfying them. The diagonal of the matrix represents the number of data points for which the predicted class is equal to the true class, and that is where almost all the data points are shows, thus the model's performance seems to be really high. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing the Decision Tree Classifier with the SVM Classifier\n",
    "\n",
    "For a better insight and comparison between the two model we can compare their confusion matrices. We can see that the Decision Tree model makes slightly less mistakes on the test set compared to the SVM, which makes it a slightly better model. However, both model's performace seems to be very good and one can choose between the two. \n",
    "\n",
    "I will save both classifiers utilize it for future predictions and deployment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# Save SVM classifier \n",
    "filename = 'svm_model.sav'\n",
    "pickle.dump(rbf_svm, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Decision Tree classifier\n",
    "filename = 'dt_model.sav'\n",
    "pickle.dump(DT_classifier, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The trained models can be used to make predictions. To see how to use them follow the steps in Readme file.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "seezenv",
   "language": "python",
   "name": "seezenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
